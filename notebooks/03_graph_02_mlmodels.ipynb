{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training machine learning models on pairs of substrates in individual organisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subpred.util import load_df\n",
    "from subpred.graph import preprocess_data, get_substrate_matrix\n",
    "from subpred.pssm import calculate_pssm_feature\n",
    "from subpred.compositions import calculate_aac, calculate_paac\n",
    "import pandas as pd\n",
    "from subpred.cdhit import cd_hit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "\n",
    "from subpred.custom_transformers import FeatureCombinator, get_feature_type_combinations\n",
    "\n",
    "from subpred.util import load_df\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_task(\n",
    "    organism_ids: set,\n",
    "    labels: set,\n",
    "    clustering_threshold: int = None,\n",
    "    dataset_folder_path: str = \"../data/datasets\",\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    (\n",
    "        df_uniprot,\n",
    "        df_uniprot_goa,\n",
    "        graph_go_filtered,\n",
    "        graph_chebi_filtered,\n",
    "    ) = preprocess_data(\n",
    "        organism_ids=organism_ids, datasets_folder_path=dataset_folder_path\n",
    "    )\n",
    "    # TODO go through method code\n",
    "    df_substrate_overlaps, dict_chebi_to_uniprot = get_substrate_matrix(\n",
    "        datasets_folder_path=dataset_folder_path,\n",
    "        graph_chebi=graph_chebi_filtered,\n",
    "        graph_go=graph_go_filtered,\n",
    "        df_uniprot_goa=df_uniprot_goa,\n",
    "        min_overlap=0,\n",
    "        max_overlap=int(1e6),\n",
    "    )\n",
    "    assert df_substrate_overlaps.shape[0] == len(dict_chebi_to_uniprot.keys())\n",
    "    chebi_name_to_term = {\n",
    "        name: term for term, name in graph_chebi_filtered.nodes(data=\"name\")\n",
    "    }\n",
    "    chebi_term_to_name = {\n",
    "        term: name for term, name in graph_chebi_filtered.nodes(data=\"name\")\n",
    "    }\n",
    "    molecule_counts = {\n",
    "        chebi_term_to_name[term]: len(proteins)\n",
    "        for term, proteins in dict_chebi_to_uniprot.items()\n",
    "    }\n",
    "    # print(sorted(molecule_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    protein_to_label = list()\n",
    "    for label in labels:\n",
    "        label_proteins = dict_chebi_to_uniprot[chebi_name_to_term[label]]\n",
    "        for protein in label_proteins:\n",
    "            protein_to_label.append([protein, label])\n",
    "\n",
    "    df_labels = pd.DataFrame.from_records(\n",
    "        protein_to_label, columns=[\"Uniprot\", \"label\"], index=\"Uniprot\"\n",
    "    )\n",
    "\n",
    "    df_labels = df_labels[~df_labels.index.duplicated()]  # TODO series?\n",
    "    df_sequences = df_uniprot.loc[df_labels.index].sequence.to_frame()\n",
    "    if clustering_threshold:\n",
    "        cluster_representatives = cd_hit(\n",
    "            df_sequences.sequence, identity_threshold=clustering_threshold\n",
    "        )\n",
    "        df_sequences = df_sequences.loc[cluster_representatives]\n",
    "        df_labels = df_labels.loc[cluster_representatives]\n",
    "    return pd.concat([df_sequences, df_labels], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(series_sequences: pd.Series):\n",
    "    df_aac = calculate_aac(series_sequences)\n",
    "    df_paac = calculate_paac(series_sequences)\n",
    "    df_pssm_50_1 = calculate_pssm_feature(\n",
    "        series_sequences,\n",
    "        tmp_folder=\"../data/intermediate/blast/pssm_uniref50_1it\",\n",
    "        blast_db=\"../data/raw/uniref/uniref50/uniref50.fasta\",\n",
    "        iterations=1,\n",
    "        psiblast_threads=-1,\n",
    "        verbose=False,\n",
    "        feature_name=\"PSSM_50_1\",\n",
    "    )\n",
    "    df_pssm_50_3 = calculate_pssm_feature(\n",
    "        series_sequences,\n",
    "        tmp_folder=\"../data/intermediate/blast/pssm_uniref50_3it\",\n",
    "        blast_db=\"../data/raw/uniref/uniref50/uniref50.fasta\",\n",
    "        iterations=3,\n",
    "        psiblast_threads=-1,\n",
    "        verbose=False,\n",
    "        feature_name=\"PSSM_50_3\",\n",
    "    )\n",
    "    df_pssm_90_1 = calculate_pssm_feature(\n",
    "        series_sequences,\n",
    "        tmp_folder=\"../data/intermediate/blast/pssm_uniref90_3it\",\n",
    "        blast_db=\"../data/raw/uniref/uniref90/uniref90.fasta\",\n",
    "        iterations=1,\n",
    "        psiblast_threads=-1,\n",
    "        verbose=False,\n",
    "        feature_name=\"PSSM_90_1\",\n",
    "    )\n",
    "    df_pssm_90_3 = calculate_pssm_feature(\n",
    "        series_sequences,\n",
    "        tmp_folder=\"../data/intermediate/blast/pssm_uniref90_3it\",\n",
    "        blast_db=\"../data/raw/uniref/uniref90/uniref90.fasta\",\n",
    "        iterations=3,\n",
    "        psiblast_threads=-1,\n",
    "        verbose=False,\n",
    "        feature_name=\"PSSM_90_3\",\n",
    "    )\n",
    "    df_features = pd.concat(\n",
    "        [\n",
    "            df_aac,\n",
    "            df_paac,\n",
    "            df_pssm_50_1,\n",
    "            df_pssm_50_3,\n",
    "            df_pssm_90_1,\n",
    "            df_pssm_90_3,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    return df_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 14,\n",
       " 16,\n",
       " 18,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 26,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 34,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 42,\n",
       " 44,\n",
       " 46,\n",
       " 48,\n",
       " 50,\n",
       " 52,\n",
       " 54,\n",
       " 56,\n",
       " 58,\n",
       " 60,\n",
       " 62,\n",
       " 64,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 76,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 90,\n",
       " 92,\n",
       " 94,\n",
       " 96,\n",
       " 98,\n",
       " 100]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2, 101, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(df_dataset, df_features):\n",
    "    # converting data to numpy\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(sorted(df_dataset.label.unique()))\n",
    "    class_labels = label_encoder.classes_\n",
    "    sample_names = df_features.index.values\n",
    "    feature_names = df_features.columns.values\n",
    "    X = df_features.values\n",
    "    y = label_encoder.transform(df_dataset.label)\n",
    "    # train test eval split\n",
    "    (\n",
    "        X_train,\n",
    "        X_eval,\n",
    "        y_train,\n",
    "        y_eval,\n",
    "        sample_names_train,\n",
    "        sample_names_eval,\n",
    "    ) = train_test_split(X, y, sample_names, test_size=0.2, random_state=1, stratify=y)\n",
    "    return (\n",
    "        X_train,\n",
    "        X_eval,\n",
    "        y_train,\n",
    "        y_eval,\n",
    "        sample_names_train,\n",
    "        sample_names_eval,\n",
    "        feature_names,\n",
    "        class_labels\n",
    "    )\n",
    "\n",
    "\n",
    "def get_model(X_train, y_train, feature_names: pd.Series, type: str = \"plain\"):\n",
    "    # types: featurecomb, anova, featurecomb_anova, plain TODO\n",
    "    feature_type_combinations = get_feature_type_combinations(\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "\n",
    "    param_grid = dict()\n",
    "    pipeline_elements = list()\n",
    "    pipeline_elements.append(StandardScaler())\n",
    "    if type in [\"featurecomb\", \"featurecomb_anova\"]:\n",
    "        pipeline_elements.append(FeatureCombinator(feature_names=feature_names))\n",
    "        param_grid.update(\n",
    "            {\"featurecombinator__feature_types\": feature_type_combinations}\n",
    "        )\n",
    "    elif type in [\"anova\", \"featurecomb_anova\"]:\n",
    "        pipeline_elements.append(SelectPercentile())\n",
    "        param_grid.update(\n",
    "            {\n",
    "                \"selectpercentile__percentile\": list(range(2, 101, 2)),\n",
    "            }\n",
    "        )  # TODO all?\n",
    "    pipeline_elements.append(SVC(random_state=1, probability=True))\n",
    "    param_grid.update(\n",
    "        {\n",
    "            \"svc__C\": [0.1, 1, 10],\n",
    "            # \"svc__gamma\": [\"scale\", \"auto\"],\n",
    "            \"svc__class_weight\": [\"balanced\", None],\n",
    "        }\n",
    "    )\n",
    "    pipeline = make_pipeline(*pipeline_elements)\n",
    "    print(pipeline)\n",
    "    print(param_grid)\n",
    "\n",
    "    # hyperparam optim & crossval\n",
    "    gridsearch = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        # scoring=[\"f1\", \"precision\", \"recall\"],\n",
    "        # refit=\"f1\",\n",
    "        scoring=\"f1\",\n",
    "        refit=True,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "        # verbose=20\n",
    "    )\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    return gridsearch\n",
    "\n",
    "\n",
    "def eval(X_eval, y_eval, model):\n",
    "    y_pred = model.predict(X_eval)\n",
    "    return classification_report(y_true=y_eval, y_pred=y_pred, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_update_dict(graph, field=\"alt_id\"):\n",
    "    dict_update_id = dict()\n",
    "    for node, alt_ids in graph.nodes(data=field):\n",
    "        if not alt_ids:\n",
    "            continue\n",
    "        for alt_id in alt_ids:\n",
    "            dict_update_id[alt_id] = node\n",
    "\n",
    "    return dict_update_id\n",
    "\n",
    "\n",
    "def get_go_subgraph(\n",
    "    root_term_name: str, edge_keys: set = {\"is_a\"}, aspects_filter: set = None\n",
    "):\n",
    "    # edge_keys: {\"is_a\"}, aspects_filter: {\"molecular_function\"}\n",
    "    graph_go = load_df(\"go_obo\")\n",
    "    go_name_to_id = {name: node for node, name in list(graph_go.nodes(data=\"name\"))}\n",
    "    root_term_id = go_name_to_id[root_term_name]\n",
    "\n",
    "    root_term_descendants = nx.ancestors(graph_go, root_term_id)\n",
    "    graph_go_sub = graph_go.subgraph(root_term_descendants)\n",
    "\n",
    "    if edge_keys:\n",
    "        graph_go_sub = graph_go_sub.edge_subgraph(\n",
    "            [\n",
    "                (node1, node2, key)\n",
    "                for node1, node2, key in graph_go_sub.edges(keys=True)\n",
    "                if key in edge_keys\n",
    "            ]\n",
    "        )\n",
    "    if aspects_filter:\n",
    "        nodes_aspects = {\n",
    "            node\n",
    "            for node, namespace in graph_go.nodes(data=\"namespace\")\n",
    "            if namespace in aspects_filter\n",
    "        }\n",
    "        graph_go_sub = graph_go_sub.subgraph(nodes_aspects)\n",
    "\n",
    "    return graph_go_sub.copy()\n",
    "\n",
    "\n",
    "# TODO turn this into new dataset creation pipeline. \n",
    "# first, get protein dataset\n",
    "# then, get goa annotations for transmembrane transporters\n",
    "# annotate with chebi terms (primary only)\n",
    "def get_goa_subset(\n",
    "    root_term_name: str,\n",
    "    proteins_filter: set = None,\n",
    "    qualifiers_filter: set = None,\n",
    "    aspects_filter: set = None,\n",
    "    evidence_codes_exclude: set = None,\n",
    "):\n",
    "    # creates subset of go annotations below a root node, and filtered by a set of proteins.\n",
    "    graph_go = load_df(\"go_obo\")\n",
    "\n",
    "    go_name_to_id = {name: node for node, name in list(graph_go.nodes(data=\"name\"))}\n",
    "    go_id_to_name = {node: name for node, name in list(graph_go.nodes(data=\"name\"))}\n",
    "    root_term_id = go_name_to_id[root_term_name]\n",
    "\n",
    "    # use is_a key for retrieving ancestors and descendants, to avoid crossing into different aspect\n",
    "    graph_go_isa = graph_go.edge_subgraph(\n",
    "        [\n",
    "            (node1, node2, key)\n",
    "            for node1, node2, key in graph_go.edges(keys=True)\n",
    "            if key == \"is_a\"\n",
    "        ]\n",
    "    )\n",
    "    root_term_descendants = nx.ancestors(graph_go_isa, root_term_id)\n",
    "\n",
    "    df_goa = load_df(\"go\")\n",
    "\n",
    "    # update go terms\n",
    "    dict_update_ids = get_id_update_dict(graph_go, field=\"alt_id\")\n",
    "    df_goa.go_id.apply(\n",
    "        lambda id: dict_update_ids[id] if id in dict_update_ids.keys() else id\n",
    "    )\n",
    "    # filter annotations\n",
    "    df_goa = df_goa[df_goa.go_id.isin(root_term_descendants)]\n",
    "    if proteins_filter:\n",
    "        df_goa = df_goa[df_goa.Uniprot.isin(proteins_filter)]\n",
    "    if qualifiers_filter:\n",
    "        df_goa = df_goa[df_goa.qualifier.isin(qualifiers_filter)]\n",
    "    if aspects_filter:\n",
    "        df_goa = df_goa[df_goa.aspect.isin(aspects_filter)]\n",
    "    if evidence_codes_exclude:\n",
    "        df_goa = df_goa[~df_goa.evidence_code.isin(evidence_codes_exclude)]\n",
    "\n",
    "    df_goa = df_goa.drop_duplicates().reset_index(drop=True)\n",
    "    df_goa[\"go_term\"] = df_goa.go_id.map(go_id_to_name)\n",
    "    df_goa[\"ancestors\"] = df_goa.go_id.apply(\n",
    "        lambda x: set(nx.descendants(graph_go_isa, x) & root_term_descendants)\n",
    "    )\n",
    "    df_goa = df_goa.explode(\"ancestors\").reset_index(drop=True)\n",
    "    df_goa[\"ancestor_term\"] = df_goa.ancestors.map(go_id_to_name)\n",
    "\n",
    "    return df_goa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO redo dataset creation pipeline. Either go terms or chebi terms as labels\n",
    "# - problems with determinism\n",
    "# - non-transporters? P05556 for example\n",
    "# - handling for multi-substrate (multi-output?)\n",
    "# TODO train four different models for each test case\n",
    "# - Only one pssm TODO\n",
    "# - Feature selector\n",
    "# - All features with percentage\n",
    "# - Eval for each\n",
    "# TODO proper evaluation\n",
    "# - cross validation with multiple scores and different positive labels\n",
    "# - test sets too small?\n",
    "# - LOOCV\n",
    "# - Nested gridsearch\n",
    "# - No test set? Only for final model?\n",
    "# TODO ROC or PrecRecCurve with all models for a test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "athaliana potassium(1+) calcium(2+)\n",
      "============================================================\n",
      "cd-hit: clustered 98 sequences into 63 clusters at threshold 70\n",
      "label\n",
      "potassium(1+)    34\n",
      "calcium(2+)      29\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "potassium(1+)    33\n",
      "calcium(2+)      29\n",
      "Name: count, dtype: int64\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(probability=True, random_state=1))])\n",
      "{'svc__C': [0.1, 1, 10], 'svc__class_weight': ['balanced', None]}\n",
      "Best training score 0.773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>calcium(2+) (0)</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.727</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium(1+) (1)</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.800</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.764</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.773</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.766</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   precision  recall  f1-score  support\n",
       "calcium(2+) (0)        0.800   0.667     0.727        6\n",
       "potassium(1+) (1)      0.750   0.857     0.800        7\n",
       "accuracy               0.769   0.769     0.769        0\n",
       "macro avg              0.775   0.762     0.764       13\n",
       "weighted avg           0.773   0.769     0.766       13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "athaliana inorganic anion inorganic cation\n",
      "============================================================\n",
      "cd-hit: clustered 312 sequences into 199 clusters at threshold 70\n",
      "label\n",
      "inorganic cation    158\n",
      "inorganic anion      41\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "inorganic cation    153\n",
      "inorganic anion      41\n",
      "Name: count, dtype: int64\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(probability=True, random_state=1))])\n",
      "{'svc__C': [0.1, 1, 10], 'svc__class_weight': ['balanced', None]}\n",
      "Best training score 0.917\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inorganic anion (0)</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.714</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inorganic cation (1)</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.937</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.826</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.892</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      precision  recall  f1-score  support\n",
       "inorganic anion (0)       0.833   0.625     0.714        8\n",
       "inorganic cation (1)      0.909   0.968     0.937       31\n",
       "accuracy                  0.897   0.897     0.897        0\n",
       "macro avg                 0.871   0.796     0.826       39\n",
       "weighted avg              0.894   0.897     0.892       39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "athaliana carboxylic acid anion inorganic anion\n",
      "============================================================\n",
      "cd-hit: clustered 127 sequences into 90 clusters at threshold 70\n",
      "label\n",
      "inorganic anion          46\n",
      "carboxylic acid anion    44\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "inorganic anion          46\n",
      "carboxylic acid anion    44\n",
      "Name: count, dtype: int64\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(probability=True, random_state=1))])\n",
      "{'svc__C': [0.1, 1, 10], 'svc__class_weight': ['balanced', None]}\n",
      "Best training score 0.737\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carboxylic acid anion (0)</th>\n",
       "      <td>0.900</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inorganic anion (1)</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.941</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.944</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.944</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           precision  recall  f1-score  support\n",
       "carboxylic acid anion (0)      0.900   1.000     0.947        9\n",
       "inorganic anion (1)            1.000   0.889     0.941        9\n",
       "accuracy                       0.944   0.944     0.944        0\n",
       "macro avg                      0.950   0.944     0.944       18\n",
       "weighted avg                   0.950   0.944     0.944       18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = {\"potassium(1+)\", \"calcium(2+)\"}\n",
    "\n",
    "dataset_name_to_organism_ids = {\n",
    "    \"human\": {9606},\n",
    "    \"athaliana\": {3702},\n",
    "    \"ecoli\": {83333},\n",
    "    \"yeast\": {559292},\n",
    "}\n",
    "dataset_name_to_organism_ids[\"all\"] = {\n",
    "    list(s)[0] for s in dataset_name_to_organism_ids.values() if len(s) == 1\n",
    "}\n",
    "\n",
    "test_cases = [\n",
    "    (\"athaliana\", \"potassium(1+)\", \"calcium(2+)\"),\n",
    "    (\"athaliana\", \"inorganic anion\", \"inorganic cation\"),\n",
    "    (\"athaliana\", \"carboxylic acid anion\", \"inorganic anion\"),\n",
    "    # (\"ecoli\", \"carbohydrate derivative\", \"monosaccharide\"),\n",
    "    # (\"ecoli\", \"monocarboxylic acid\", \"amino acid\"),\n",
    "    # (\"human\", \"calcium(2+)\", \"sodium(1+)\"),\n",
    "    # (\"human\", \"calcium(2+)\", \"potassium(1+)\"),\n",
    "    # (\"human\", \"sodium(1+)\", \"potassium(1+)\"),\n",
    "    # (\"human\", \"inorganic anion\", \"inorganic cation\"),\n",
    "    # (\"yeast\", \"amide\", \"amino acid derivative\"),\n",
    "]\n",
    "\n",
    "for dataset_name, substrate1, substrate2 in test_cases:\n",
    "    print(\"=\" * 60)\n",
    "    print(dataset_name, substrate1, substrate2)\n",
    "    print(\"=\" * 60)\n",
    "    organism_ids = dataset_name_to_organism_ids[dataset_name]\n",
    "    df_dataset = get_classification_task(\n",
    "        organism_ids=organism_ids,\n",
    "        labels={substrate1, substrate2},\n",
    "        clustering_threshold=70,\n",
    "    )\n",
    "    print(df_dataset.label.value_counts())\n",
    "\n",
    "    # TODO this is a quickfix, redo pipeline\n",
    "    tmtp_proteins = get_goa_subset(\n",
    "        root_term_name=\"transmembrane transporter activity\",\n",
    "        qualifiers_filter=[\"enables\"],\n",
    "        aspects_filter=[\"F\"],\n",
    "        proteins_filter=df_dataset.index.tolist(),\n",
    "    ).Uniprot.unique()\n",
    "    df_dataset = df_dataset[df_dataset.index.isin(set(tmtp_proteins))]\n",
    "    print(df_dataset.label.value_counts())\n",
    "    # TODO quickfix end\n",
    "\n",
    "    df_features = get_features(df_dataset.sequence)\n",
    "    df_features = df_features.loc[df_features.index.sort_values()]\n",
    "    df_dataset = df_dataset.loc[df_features.index]\n",
    "    df_features = df_features.loc[df_dataset.index]\n",
    "\n",
    "    (\n",
    "        X_train,\n",
    "        X_eval,\n",
    "        y_train,\n",
    "        y_eval,\n",
    "        sample_names_train,\n",
    "        sample_names_eval,\n",
    "        feature_names,\n",
    "        class_labels,\n",
    "    ) = get_xy(df_dataset=df_dataset, df_features=df_features)\n",
    "\n",
    "    model = get_model(\n",
    "        X_train=X_train, y_train=y_train, feature_names=feature_names, type=\"plain\"\n",
    "    )\n",
    "    df_cv_results = pd.DataFrame.from_dict(model.cv_results_)\n",
    "\n",
    "    print(\"Best training CV score\", round(model.best_score_, 3))\n",
    "\n",
    "    # independent test set\n",
    "    eval_results = eval(X_eval=X_eval, y_eval=y_eval, model=model.best_estimator_)\n",
    "    df_eval_results = pd.DataFrame.from_dict(eval_results).T.round(3)\n",
    "    df_eval_results[\"support\"] = df_eval_results.support.astype(int)\n",
    "    class_to_classlabel = {\n",
    "        str(number): label + f\" ({number})\" for number, label in enumerate(class_labels)\n",
    "    }\n",
    "    df_eval_results = df_eval_results.rename(index=class_to_classlabel)\n",
    "\n",
    "    df_eval_results.rename(columns={\"support\": \"n_samples\"})\n",
    "    display(df_eval_results)\n",
    "    # y_pred = model.predict(X_train)\n",
    "    # y_score = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    # print(precision_score(y_train, y_pred, pos_label=1))\n",
    "    # print(precision_score(y_train, y_pred, pos_label=0))\n",
    "    # print(recall_score(y_train, y_pred, pos_label=1))\n",
    "    # print(recall_score(y_train, y_pred, pos_label=0))\n",
    "    # print(f1_score(y_train, y_pred, pos_label=1))\n",
    "    # print(f1_score(y_train, y_pred, pos_label=0))\n",
    "    # print(roc_auc_score(y_train, y_score))\n",
    "    # print(roc_auc_score(y_train, y_score))\n",
    "\n",
    "    # display(df_cv_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "\n",
    "Compare training results with: \n",
    "\n",
    "- Average sequence similarity\n",
    "  - blast\n",
    "- GO term similarity\n",
    "  - How many protein in common?\n",
    "  - Semantic similarity?\n",
    "- CHebi similarity \n",
    "  - Smiles\n",
    "- Annotation overlap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subpred4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
